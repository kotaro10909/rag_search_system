from langchain.chains import RetrievalQA
from langchain.schema import (SystemMessage, HumanMessage, AIMessage)
from langchain_google_genai import ChatGoogleGenerativeAI, GoogleGenerativeAIEmbeddings
from langchain_community.vectorstores import FAISS
import os
import streamlit as st
from langchain.prompts import ChatPromptTemplate
from langchain.prompts.chat import (
    ChatPromptTemplate,
    SystemMessagePromptTemplate,
    HumanMessagePromptTemplate,
)
from langchain.prompts import PromptTemplate
from langchain_community.chat_models import ChatOllama
from langchain.embeddings import HuggingFaceEmbeddings

os.makedirs(".streamlit", exist_ok=True)
# config.toml ã®å†…å®¹
config_text = """
[theme]
base = "light"
primaryColor = "#1a73e8"
backgroundColor = "#f5f5f5"
secondaryBackgroundColor = "#f0f2f6"
textColor = "#333333"
font = "monospace"
"""
# ãƒ•ã‚¡ã‚¤ãƒ«æ›¸ãè¾¼ã¿
with open(".streamlit/config.toml", "w") as f:
    f.write(config_text)

print("âœ… .streamlit/config.toml ã‚’ä½œæˆã—ã¾ã—ãŸ")

def app_login():
    # æœªãƒ­ã‚°ã‚¤ãƒ³æ™‚ã®è¡¨ç¤º
    if not st.user.is_logged_in:
        if st.button("Googleã§ãƒ­ã‚°ã‚¤ãƒ³"):
             st.cache_data.clear()
             st.login()
             st.rerun()

def user_check():
    allowed_emails = st.secrets["access"]["allowed_emails"]
    if st.user.email not in allowed_emails:
        st.error("ã“ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«ã¯ã‚¢ã‚¯ã‚»ã‚¹æ¨©é™ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
        if st.button("åˆ¥ã®ã‚¢ã‚«ã‚¦ãƒ³ãƒˆã§ãƒ­ã‚°ã‚¤ãƒ³"):
             st.logout()
             st.cache_data.clear()
             st.rerun()
        return True
    return False

def app_logout():
        if st.button("ãƒ­ã‚°ã‚¢ã‚¦ãƒˆ"):
            st.logout()
            st.cache_data.clear()
            st.rerun()

def load_db(embeddings):
    return FAISS.load_local('faiss_store', embeddings, allow_dangerous_deserialization=True)


def init_page():
    st.set_page_config(
        page_title='FRACTAL AI SEARCH',
        page_icon='ğŸ§‘â€ğŸ’»',
    )


def main():
    init_page()
  # if not st.user.is_logged_in:
  #   app_login()
  # else:
  #   if user_check():
  #       return
  #   app_logout()
    # embeddings = GoogleGenerativeAIEmbeddings(
    #     model="models/embedding-001"
    # )
    # db = load_db(embeddings)
    # llm = ChatGoogleGenerativeAI(
    #     model="gemini-2.0-flash-lite",
    #     temperature=0.0,
    #     max_retries=2,
    # )
    
    embeddings = HuggingFaceEmbeddings(
        model_name="sentence-transformers/all-MiniLM-L6-v2"
    )
    db = load_db(embeddings)
    llm = ChatOllama(
        model="llama2:7b",
        temperature=0.0
    )

    # ã‚ªãƒªã‚¸ãƒŠãƒ«ã®System Instructionã‚’å®šç¾©ã™ã‚‹

    # prompt_template = """
    # ã‚ãªãŸã¯ã€ã€ŒåŒ—è¾°ç‰©ç”£ã€ã¨ã„ã†å›£ä½“å°‚ç”¨ã®ãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆã§ã™ã€‚
    # èƒŒæ™¯æƒ…å ±ã‚’å‚è€ƒã«ã€è³ªå•ã«å¯¾ã—ã¦å›£ä½“ã®äººé–“ã«ãªã‚Šãã£ã¦ã€è³ªå•ã«å›ç­”ã—ã¦ãã ã„ã€‚è§£ç­”ã®æœ€å¾Œã§ã€å‚ç…§ã—ãŸURLãŒåˆ†ã‹ã‚Œã°ãã‚Œã‚’ç­”ãˆã¦ãã ã•ã„ã€‚
    # ä»¥ä¸‹ã®èƒŒæ™¯æƒ…å ±ã‚’å‚ç…§ã—ã¦ãã ã•ã„ã€‚èƒŒæ™¯æƒ…å ±ã¨é–¢ä¿‚ã®ã‚ã‚‹è³ªå•ã«ã¯ç­”ãˆã¦ãã ã•ã„ã€‚
    # æƒ…å ±ãŒãªã‘ã‚Œã°ã€ãã®å†…å®¹ã«ã¤ã„ã¦ã¯è¨€åŠã—ãªã„ã§ãã ã•ã„ã€‚
    # # èƒŒæ™¯æƒ…å ±
    # {context}

    # # è³ªå•
    # {question}"""
    prompt_template = """
    ã‚ãªãŸã¯ã€ã€Œãƒ•ãƒ©ã‚¯ã‚¿ãƒ«å»ºç¯‰ã€ã¨ã„ã†å›£ä½“å°‚ç”¨ã®ãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆã§ã™ã€‚
    èƒŒæ™¯æƒ…å ±ã‚’å‚è€ƒã«ã€è³ªå•ã«å¯¾ã—ã¦å›£ä½“ã®äººé–“ã«ãªã‚Šãã£ã¦ã€è³ªå•ã«å›ç­”ã—ã¦ãã ã„ã€‚å›ç­”æƒ…å ±ã¨å¯¾å¿œã™ã‚‹CSVã®ã‚«ãƒ©ãƒ ã®æƒ…å ±ã‚‚åŠ ãˆã¦ãã ã•ã„ã€‚
    ä»¥ä¸‹ã®èƒŒæ™¯æƒ…å ±ã‚’å‚ç…§ã—ã¦ãã ã•ã„ã€‚èƒŒæ™¯æƒ…å ±ã¨é–¢ä¿‚ã®ã‚ã‚‹è³ªå•ã«ã¯ç­”ãˆã¦ãã ã•ã„ã€‚
    æƒ…å ±ãŒãªã‘ã‚Œã°ã€ãã®å†…å®¹ã«ã¤ã„ã¦ã¯è¨€åŠã—ãªã„ã§ãã ã•ã„ã€‚
    # èƒŒæ™¯æƒ…å ±
    {context}

    # è³ªå•
    {question}"""
    PROMPT = PromptTemplate(
        template=prompt_template, input_variables=["context", "question"]
    )
    qa = RetrievalQA.from_chain_type(
        llm=llm,
        chain_type="stuff",
        retriever=db.as_retriever(search_kwargs={"k": 3}),
        return_source_documents=True,
        chain_type_kwargs={"prompt": PROMPT}# ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’è¿½åŠ 
    )

    # ä¸ŠåŠåˆ†ã«èª¬æ˜æ–‡ã¨ãƒªãƒ³ã‚¯ã‚’é…ç½®
    # HTMLã‚¿ã‚°ã‚’ãã®ã¾ã¾ä½¿ã£ã¦ã‚¹ã‚¿ã‚¤ãƒ«ã‚’é©ç”¨
    st.markdown("""
        <style>
        .chat-box1 {
            overflow-y: auto;
            border: 2px solid #ddd;
            padding: 20px;
            border-radius: 8px;
            background-color: none;
            margin-bottom: 20px;
            text-align: center;
            background-color = #f5f5f5;
            font: monospace;
            color: #333333;
        }
        .chat-box1 h1{
            color: #00536D;
        }
        </style>
        """, unsafe_allow_html=True)

    # ç›´æ¥HTMLè¦ç´ ã‚’è¡¨ç¤º
    st.markdown("""
        <div class="chat-box1">
            <h1>FRACTAL AI SEARCH</h1>
            <p>ã“ã®AIãƒãƒ£ãƒƒãƒˆã‚¢ãƒ—ãƒªã¯ã€ç¤¾å†…æƒ…å ±ã‚’æ¤œç´¢ã™ã‚‹ãŸã‚ã®ã‚‚ã®ã§ã™ã€‚</p>
            <p>åŒ—è¾°ç‰©ç”£æ ªå¼ä¼šç¤¾ã«é–¢ã™ã‚‹è³ªå•ä»¥å¤–ã«ã¯ãŠç­”ãˆã§ãã¾ã›ã‚“ã€‚</p>
            <a href="#">ç¤¾å†…ãƒãƒ¼ã‚¿ãƒ«ã‚µã‚¤ãƒˆ</a>
        </div>
    """, unsafe_allow_html=True)

    # ä¸‹åŠåˆ†ã«ãƒãƒ£ãƒƒãƒˆç”»é¢ã‚’é…ç½®
    if "messages" not in st.session_state:
      st.session_state.messages = []
    if user_input := st.chat_input('è³ªå•ã—ã‚ˆã†ï¼'):
        # ä»¥å‰ã®ãƒãƒ£ãƒƒãƒˆãƒ­ã‚°ã‚’è¡¨ç¤º
        for message in st.session_state.messages:
            with st.chat_message(message["role"]):
                st.markdown(message["content"])
        print(user_input)
        with st.chat_message('user'):
            st.markdown(user_input)
        st.session_state.messages.append({"role": "user", "content": user_input})
        with st.chat_message('assistant'):
            with st.spinner('Gemini is typing ...'):
                response = qa.invoke(user_input)
            st.markdown(response['result'])
            #å‚è€ƒå…ƒã‚’è¡¨ç¤º
            # doc_urls = []
            # doc_pdfs = []
            # for doc in response["source_documents"]:
            #     #æ—¢ã«å‡ºåŠ›ã—ãŸã®ã¯ã€å‡ºåŠ›ã—ãªã„
            #     if "source_url" in doc.metadata and doc.metadata["source_url"] not in doc_urls:
            #         doc_urls.append(doc.metadata["source_url"])
            #         st.markdown(f"å‚è€ƒå…ƒï¼š{doc.metadata['source_url']}")
            #     elif "source_pdf" in doc.metadata and doc.metadata["source_pdf"] not in doc_pdfs:
            #         doc_pdfs.append(doc.metadata["source_pdf"])
            #         st.markdown(f"å‚è€ƒå…ƒï¼š{doc.metadata['source_pdf']}")
        st.session_state.messages.append({"role": "assistant", "content": response["result"]})


if __name__ == "__main__":
  main()
